{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score, f1_score, classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_column_names(df_copy):\n",
    "    column_list = ['label']\n",
    "    row, column = 1,1;\n",
    "    while row < 29:\n",
    "        while column < 29:\n",
    "            column_name = str(row) + 'x' + str(column)\n",
    "            column_list.append(column_name)\n",
    "            column+=1\n",
    "        row+=1;\n",
    "        if(column == 29):\n",
    "            column = 1\n",
    "            \n",
    "    df_copy.columns = column_list\n",
    "    return df_copy\n",
    "\n",
    "def split_dataset_to_train_test_validation(df_copy, train_sze, test_sze, validation_sze):\n",
    "    random.seed(0)\n",
    "    target_column = ['label']\n",
    "    predictors = list(set(list(df.columns))-set(target_column))\n",
    "    X = df_copy[predictors].values #Contains all columns\n",
    "    Y = df_copy[['label']].values\n",
    "    X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, train_size=train_sze, random_state=50)\n",
    "    X_test, X_validation, Y_test, Y_validation = train_test_split(X_temp, Y_temp, train_size=test_sze/(test_sze+validation_sze), random_state=50)\n",
    "    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "df_train = pd.read_csv('MNIST_TRAIN.csv')\n",
    "df_test = pd.read_csv('MNIST_TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_train.isnull().sum().sum()); print(df_test.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...  28x19  28x20  \\\n",
      "0        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "1        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "2        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "3        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "4        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...    ...    ...   \n",
      "59995    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "59996    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "59997    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "59998    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "59999    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "\n",
      "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0          0      0      0      0      0      0      0      0  \n",
      "1          0      0      0      0      0      0      0      0  \n",
      "2          0      0      0      0      0      0      0      0  \n",
      "3          0      0      0      0      0      0      0      0  \n",
      "4          0      0      0      0      0      0      0      0  \n",
      "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "59995      0      0      0      0      0      0      0      0  \n",
      "59996      0      0      0      0      0      0      0      0  \n",
      "59997      0      0      0      0      0      0      0      0  \n",
      "59998      0      0      0      0      0      0      0      0  \n",
      "59999      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[60000 rows x 784 columns]\n",
      "      1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...  28x19  28x20  \\\n",
      "0       0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "1       0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "2       0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "3       0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "4       0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...    ...    ...   \n",
      "9995    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "9996    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "9997    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "9998    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "9999    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "\n",
      "      28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0         0      0      0      0      0      0      0      0  \n",
      "1         0      0      0      0      0      0      0      0  \n",
      "2         0      0      0      0      0      0      0      0  \n",
      "3         0      0      0      0      0      0      0      0  \n",
      "4         0      0      0      0      0      0      0      0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9995      0      0      0      0      0      0      0      0  \n",
      "9996      0      0      0      0      0      0      0      0  \n",
      "9997      0      0      0      0      0      0      0      0  \n",
      "9998      0      0      0      0      0      0      0      0  \n",
      "9999      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[10000 rows x 784 columns]\n",
      "---------------------------------------------------------------\n",
      "       label\n",
      "0          5\n",
      "1          0\n",
      "2          4\n",
      "3          1\n",
      "4          9\n",
      "...      ...\n",
      "59995      8\n",
      "59996      3\n",
      "59997      5\n",
      "59998      6\n",
      "59999      8\n",
      "\n",
      "[60000 rows x 1 columns]\n",
      "      label\n",
      "0         7\n",
      "1         2\n",
      "2         1\n",
      "3         0\n",
      "4         4\n",
      "...     ...\n",
      "9995      2\n",
      "9996      3\n",
      "9997      4\n",
      "9998      5\n",
      "9999      6\n",
      "\n",
      "[10000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.drop('label', axis = 1)\n",
    "X_test = df_test.drop('label', axis = 1)\n",
    "print(X_train); print(X_test);\n",
    "\n",
    "print('---------------------------------------------------------------')\n",
    "\n",
    "Y_train = df_train[['label']]\n",
    "Y_test = df_test[['label']]\n",
    "print(Y_train); print(Y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(784,15,15,10), activation='relu', solver='adam', batch_size=16, max_iter=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.30221786\n",
      "Iteration 2, loss = 0.11735696\n",
      "Iteration 3, loss = 0.08801870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(batch_size=16, hidden_layer_sizes=(784, 15, 15, 10), max_iter=3,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Train Set:\n",
      "[[5858    0    9    1    4    2   25    6    6   12]\n",
      " [   0 6667   49    2    3    0    0   15    6    0]\n",
      " [   6    1 5909   10   14    0    2   11    4    1]\n",
      " [   0    2   50 6040    0    3    0    7   15   14]\n",
      " [   3    2    3    0 5807    0    4    6    1   16]\n",
      " [   4    1    1   63    0 5266   36    3   20   27]\n",
      " [  10    2    5    1    9    2 5885    0    3    1]\n",
      " [   1   10   30    3    5    0    0 6204    3    9]\n",
      " [   3   15   54   10    5    6   14    5 5731    8]\n",
      " [   4    2    1   13   53    2    0   45    9 5820]]\n",
      "Classification Report of Train Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5923\n",
      "           1       0.99      0.99      0.99      6742\n",
      "           2       0.97      0.99      0.98      5958\n",
      "           3       0.98      0.99      0.98      6131\n",
      "           4       0.98      0.99      0.99      5842\n",
      "           5       1.00      0.97      0.98      5421\n",
      "           6       0.99      0.99      0.99      5918\n",
      "           7       0.98      0.99      0.99      6265\n",
      "           8       0.99      0.98      0.98      5851\n",
      "           9       0.99      0.98      0.98      5949\n",
      "\n",
      "    accuracy                           0.99     60000\n",
      "   macro avg       0.99      0.99      0.99     60000\n",
      "weighted avg       0.99      0.99      0.99     60000\n",
      "\n",
      "------------------------------------------\n",
      "Confusion Matrix of Test Set:\n",
      "[[ 964    0    2    1    0    0    3    4    3    3]\n",
      " [   0 1123    9    0    0    1    0    0    2    0]\n",
      " [   0    0 1016    1    5    0    2    5    2    1]\n",
      " [   0    0    6  989    0    1    0    5    5    4]\n",
      " [   0    0    4    0  964    0    4    2    0    8]\n",
      " [   2    0    0   23    1  852    3    0    4    7]\n",
      " [   4    2    1    1    8    2  937    0    3    0]\n",
      " [   0    0   14    3    1    0    0 1001    2    7]\n",
      " [   2    0   12    3    2    3    5    4  938    5]\n",
      " [   3    2    0    8   15    1    1    9    2  968]]\n",
      "Classification Report of Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       980\n",
      "           1       1.00      0.99      0.99      1135\n",
      "           2       0.95      0.98      0.97      1032\n",
      "           3       0.96      0.98      0.97      1010\n",
      "           4       0.97      0.98      0.97       982\n",
      "           5       0.99      0.96      0.97       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.97      0.97      0.97      1028\n",
      "           8       0.98      0.96      0.97       974\n",
      "           9       0.97      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.97      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix of Train Set:'); print(confusion_matrix(Y_train, predict_train))\n",
    "print('Classification Report of Train Set:'); print(classification_report(Y_train, predict_train))\n",
    "\n",
    "print('------------------------------------------')\n",
    "\n",
    "print('Confusion Matrix of Test Set:'); print(confusion_matrix(Y_test, predict_test))\n",
    "print('Classification Report of Test Set:'); print(classification_report(Y_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the train set: \n",
      "0.98645\n",
      "Score of the test set: \n",
      "0.9752\n"
     ]
    }
   ],
   "source": [
    "print('Score of the train set: '); print(mlp.score(X_train, Y_train))\n",
    "print('Score of the test set: '); print(mlp.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
