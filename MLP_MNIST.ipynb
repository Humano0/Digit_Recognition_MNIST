{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score, f1_score, classification_report\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_column_names(df_copy):\n",
    "    column_list = ['label']\n",
    "    row, column = 1,1;\n",
    "    while row < 29:\n",
    "        while column < 29:\n",
    "            column_name = str(row) + 'x' + str(column)\n",
    "            column_list.append(column_name)\n",
    "            column+=1\n",
    "        row+=1;\n",
    "        if(column == 29):\n",
    "            column = 1\n",
    "            \n",
    "    df_copy.columns = column_list\n",
    "    return df_copy\n",
    "\n",
    "def split_dataset_to_train_test_validation(df_copy, train_sze, test_sze, validation_sze):\n",
    "    random.seed(0)\n",
    "    target_column = ['label']\n",
    "    predictors = list(set(list(df.columns))-set(target_column))\n",
    "    X = df_copy[predictors].values #Contains all columns\n",
    "    Y = df_copy[['label']].values\n",
    "    X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, train_size=train_sze, random_state=50)\n",
    "    X_test, X_validation, Y_test, Y_validation = train_test_split(X_temp, Y_temp, train_size=test_sze/(test_sze+validation_sze), random_state=50)\n",
    "    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "df_train = pd.read_csv('MNIST_TRAIN.csv')\n",
    "df_test = pd.read_csv('MNIST_TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_train.isnull().sum().sum()); print(df_test.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...  28x19  28x20  \\\n",
      "0        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "1        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "2        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "3        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "4        0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...    ...    ...   \n",
      "59995    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "59996    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "59997    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "59998    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "59999    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "\n",
      "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0          0      0      0      0      0      0      0      0  \n",
      "1          0      0      0      0      0      0      0      0  \n",
      "2          0      0      0      0      0      0      0      0  \n",
      "3          0      0      0      0      0      0      0      0  \n",
      "4          0      0      0      0      0      0      0      0  \n",
      "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "59995      0      0      0      0      0      0      0      0  \n",
      "59996      0      0      0      0      0      0      0      0  \n",
      "59997      0      0      0      0      0      0      0      0  \n",
      "59998      0      0      0      0      0      0      0      0  \n",
      "59999      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[60000 rows x 784 columns]\n",
      "      1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...  28x19  28x20  \\\n",
      "0       0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "1       0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "2       0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "3       0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "4       0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...    ...    ...   \n",
      "9995    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "9996    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "9997    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "9998    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "9999    0    0    0    0    0    0    0    0    0     0  ...      0      0   \n",
      "\n",
      "      28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0         0      0      0      0      0      0      0      0  \n",
      "1         0      0      0      0      0      0      0      0  \n",
      "2         0      0      0      0      0      0      0      0  \n",
      "3         0      0      0      0      0      0      0      0  \n",
      "4         0      0      0      0      0      0      0      0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9995      0      0      0      0      0      0      0      0  \n",
      "9996      0      0      0      0      0      0      0      0  \n",
      "9997      0      0      0      0      0      0      0      0  \n",
      "9998      0      0      0      0      0      0      0      0  \n",
      "9999      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[10000 rows x 784 columns]\n",
      "---------------------------------------------------------------\n",
      "       label\n",
      "0          5\n",
      "1          0\n",
      "2          4\n",
      "3          1\n",
      "4          9\n",
      "...      ...\n",
      "59995      8\n",
      "59996      3\n",
      "59997      5\n",
      "59998      6\n",
      "59999      8\n",
      "\n",
      "[60000 rows x 1 columns]\n",
      "      label\n",
      "0         7\n",
      "1         2\n",
      "2         1\n",
      "3         0\n",
      "4         4\n",
      "...     ...\n",
      "9995      2\n",
      "9996      3\n",
      "9997      4\n",
      "9998      5\n",
      "9999      6\n",
      "\n",
      "[10000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.drop('label', axis = 1)\n",
    "X_test = df_test.drop('label', axis = 1)\n",
    "print(X_train); print(X_test);\n",
    "\n",
    "print('---------------------------------------------------------------')\n",
    "\n",
    "Y_train = df_train[['label']]\n",
    "Y_test = df_test[['label']]\n",
    "print(Y_train); print(Y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(784,64,32,16,10), activation='relu', solver='adam', batch_size=16, max_iter=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.30188836\n",
      "Iteration 2, loss = 0.11441309\n",
      "Iteration 3, loss = 0.08748982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(batch_size=16, hidden_layer_sizes=(784, 64, 32, 16, 10),\n",
       "              max_iter=3, verbose=True)"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = mlp.predict(X_train)\n",
    "predict_test = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Train Set:\n",
      "[[5878    0    5    1    0    0   25    1   11    2]\n",
      " [   0 6709    7    4    3    0    5    6    7    1]\n",
      " [  13    8 5885   14    9    0    0   13   13    3]\n",
      " [   2    4   36 6043    0   14    0    7   17    8]\n",
      " [   3    1    2    0 5766    1   13    3    5   48]\n",
      " [  10    1    1   69    1 5287   33    0   17    2]\n",
      " [   5    0    1    0    3    5 5899    0    5    0]\n",
      " [   7   14   19   12    5    4    3 6146    6   49]\n",
      " [   2   17   14   17    0   14   19    2 5752   14]\n",
      " [  10    3    1   73   16   26    0   19   11 5790]]\n",
      "Classification Report of Train Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5923\n",
      "           1       0.99      1.00      0.99      6742\n",
      "           2       0.99      0.99      0.99      5958\n",
      "           3       0.97      0.99      0.98      6131\n",
      "           4       0.99      0.99      0.99      5842\n",
      "           5       0.99      0.98      0.98      5421\n",
      "           6       0.98      1.00      0.99      5918\n",
      "           7       0.99      0.98      0.99      6265\n",
      "           8       0.98      0.98      0.98      5851\n",
      "           9       0.98      0.97      0.98      5949\n",
      "\n",
      "    accuracy                           0.99     60000\n",
      "   macro avg       0.99      0.99      0.99     60000\n",
      "weighted avg       0.99      0.99      0.99     60000\n",
      "\n",
      "------------------------------------------\n",
      "Confusion Matrix of Test Set:\n",
      "[[ 969    0    1    2    0    0    4    0    3    1]\n",
      " [   0 1125    1    0    0    0    3    0    6    0]\n",
      " [   6    1 1007    4    5    0    1    5    1    2]\n",
      " [   0    0    3  996    0    3    0    4    4    0]\n",
      " [   1    1    0    0  964    0    2    2    1   11]\n",
      " [   3    0    0   21    1  852    9    0    5    1]\n",
      " [   3    2    0    1    1    3  945    0    3    0]\n",
      " [   1    5    5    7    1    1    0  993    2   13]\n",
      " [   1    1    7    8    1    4    4    3  941    4]\n",
      " [   4    4    1   17   10    3    0    2    1  967]]\n",
      "Classification Report of Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.94      0.99      0.96      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.98      0.96      0.97       892\n",
      "           6       0.98      0.99      0.98       958\n",
      "           7       0.98      0.97      0.97      1028\n",
      "           8       0.97      0.97      0.97       974\n",
      "           9       0.97      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix of Train Set:'); print(confusion_matrix(Y_train, predict_train))\n",
    "print('Classification Report of Train Set:'); print(classification_report(Y_train, predict_train))\n",
    "\n",
    "print('------------------------------------------')\n",
    "\n",
    "print('Confusion Matrix of Test Set:'); print(confusion_matrix(Y_test, predict_test))\n",
    "print('Classification Report of Test Set:'); print(classification_report(Y_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the train set: \n",
      "0.9859166666666667\n",
      "Score of the test set: \n",
      "0.9759\n"
     ]
    }
   ],
   "source": [
    "print('Score of the train set: '); print(mlp.score(X_train, Y_train))\n",
    "print('Score of the test set: '); print(mlp.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
