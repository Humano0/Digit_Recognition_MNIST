{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_column_names(df_copy):\n",
    "    column_list = ['label']\n",
    "    row, column = 1,1;\n",
    "    while row < 29:\n",
    "        while column < 29:\n",
    "            column_name = str(row) + 'x' + str(column)\n",
    "            column_list.append(column_name)\n",
    "            column+=1\n",
    "        row+=1;\n",
    "        if(column == 29):\n",
    "            column = 1\n",
    "            \n",
    "    df_copy.columns = column_list\n",
    "    return df_copy\n",
    "\n",
    "def split_dataset_to_train_test_validation(df_copy, train_sze, test_sze, validation_sze):\n",
    "    random.seed(0)\n",
    "    target_column = ['label']\n",
    "    predictors = list(set(list(df.columns))-set(target_column))\n",
    "    X = df_copy[predictors] #Contains all columns\n",
    "    Y = df_copy[['label']]\n",
    "    X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, train_size=train_sze, random_state=50)\n",
    "    X_test, X_validation, Y_test, Y_validation = train_test_split(X_temp, Y_temp, train_size=test_sze/(test_sze+validation_sze), random_state=50)\n",
    "    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n",
    "\n",
    "def normalizer(dataframe):\n",
    "    result = dataframe.copy()/255\n",
    "    return result\n",
    "\n",
    "def model():\n",
    "    inputs = Input(shape=(28,28,1))\n",
    "    Conv2D(24,kernel_size=(3,3),padding='same',activation=\"relu\", input_shape = (28,28,1))\n",
    "    MaxPooling2D(pool_size=(2, 2))\n",
    "    Conv2D(48, (3, 3), padding='same',activation='relu', input_shape = (28,28,1))\n",
    "    MaxPooling2D(pool_size=(2, 2))\n",
    "    Conv2D(64, (3, 3), padding='same',activation='relu', input_shape = (28,28,1))\n",
    "    MaxPooling2D(pool_size=(2, 2))\n",
    "    Flatten()\n",
    "    Dense(128, activation='relu')\n",
    "    Dropout(0.25)\n",
    "    output = Dense(10,activation=\"softmax\")\n",
    "    \n",
    "    model = Model(inputs,output)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('MNIST_TRAIN.csv')\n",
    "df_test = pd.read_csv('MNIST_TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of NaN values in training set: \n",
      "0\n",
      "Numbers of NaN values in test set: \n",
      "0\n",
      "       label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
      "0          5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "1          0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "2          4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3          1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "4          9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
      "59995      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "59996      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "59997      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "59998      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "59999      8    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "\n",
      "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0          0      0      0      0      0      0      0      0  \n",
      "1          0      0      0      0      0      0      0      0  \n",
      "2          0      0      0      0      0      0      0      0  \n",
      "3          0      0      0      0      0      0      0      0  \n",
      "4          0      0      0      0      0      0      0      0  \n",
      "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "59995      0      0      0      0      0      0      0      0  \n",
      "59996      0      0      0      0      0      0      0      0  \n",
      "59997      0      0      0      0      0      0      0      0  \n",
      "59998      0      0      0      0      0      0      0      0  \n",
      "59999      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[60000 rows x 785 columns]\n",
      "      label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
      "0         7    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "1         2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "2         1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3         0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "4         4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
      "9995      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "9996      3    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "9997      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "9998      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "9999      6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "\n",
      "      28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0         0      0      0      0      0      0      0      0  \n",
      "1         0      0      0      0      0      0      0      0  \n",
      "2         0      0      0      0      0      0      0      0  \n",
      "3         0      0      0      0      0      0      0      0  \n",
      "4         0      0      0      0      0      0      0      0  \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9995      0      0      0      0      0      0      0      0  \n",
      "9996      0      0      0      0      0      0      0      0  \n",
      "9997      0      0      0      0      0      0      0      0  \n",
      "9998      0      0      0      0      0      0      0      0  \n",
      "9999      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[10000 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "print('Numbers of NaN values in training set: '); print(df_train.isnull().sum().sum()); \n",
    "print('Numbers of NaN values in test set: '); print(df_test.isnull().sum().sum());\n",
    "print(df_train); print(df_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('label', axis = 1)\n",
    "Y_train = df_train[['label']]\n",
    "\n",
    "X_test = df_test.drop('label', axis = 1)\n",
    "Y_test = df_test[['label']]\n",
    "\n",
    "X_train = normalizer(X_train); X_test = normalizer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(784, activation='sigmoid'))\n",
    "model.add(Dense(16, activation='sigmoid'))\n",
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 07:48:26.777400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-06-27 07:48:26.794294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:5e:00.0\n",
      "2022-06-27 07:48:26.795488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: Tesla V100-PCIE-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:af:00.0\n",
      "2022-06-27 07:48:26.795816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2022-06-27 07:48:26.797630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2022-06-27 07:48:26.799290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2022-06-27 07:48:26.799720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2022-06-27 07:48:26.801823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2022-06-27 07:48:26.803324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2022-06-27 07:48:26.808104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-27 07:48:26.812571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train.values, Y_train.values, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.test.is_gpu_available())\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
